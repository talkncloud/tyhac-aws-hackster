{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import torch\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "account_id = role.split(':')[4]\n",
    "sess = sagemaker.Session()\n",
    "region = boto3.session.Session().region_name\n",
    "print(\"Region = {}\".format(region))\n",
    "    \n",
    "sm = boto3.Session().client('sagemaker')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!sudo apt-get install -y libsndfile1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "modelfolder = \"tyhac-fastai-2021-08-22-10-37-01-521\"\n",
    "rawbucket = sess.default_bucket()\n",
    "model_artefact = f's3://{rawbucket}/sagemaker-covid-tyhac-fastai/models/{modelfolder}/output/model.tar.gz'\n",
    "print(model_artefact)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# optionally download the model archive locally\n",
    "# !mkdir {modelfolder}\n",
    "filename = modelfolder + '/' + 'model.tar.gz'\n",
    "!aws s3 cp {model_artefact} {filename}\n",
    "!tar -zxvf {filename} -C {modelfolder} 'export.pkl' 'roc_curve.jpg' 'confusion_matrix.jpg' 'dataset_test.csv'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# %%writefile inference/serve.py\n",
    "import logging, requests, os, io, glob, time, pathlib\n",
    "from fastai.vision.all import *\n",
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "JSON_CONTENT_TYPE = 'application/json'\n",
    "# JPEG_CONTENT_TYPE = 'image/jpeg'\n",
    "\n",
    "# loads the model into memory from disk and returns it\n",
    "def model_fn(model_dir):\n",
    "    logger.info('model_fn')\n",
    "    path = Path(model_dir)\n",
    "    learn = load_learner(model_dir + '/export.pkl')\n",
    "    logger.info('TYHAC: Model has been loaded')\n",
    "    return learn\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    logger.info('TYHAC: Deserializing the input data.')\n",
    "    \n",
    "    if request_content_type == 'text/csv':\n",
    "        tmp=request_body\n",
    "        print('tyhac body: ', tmp)\n",
    "        bucket=tmp[:tmp.index('/')]\n",
    "        print(\"bucket: {}\".format(bucket))\n",
    "        obj=tmp[tmp.index('/')+1:]\n",
    "        print(\"object: {}\".format(obj))\n",
    "        file = s3.download_file(bucket, obj, 'audioinput.wav')\n",
    "        print(\"audio input file size: {}\".format(os.path.getsize('audioinput.wav')))\n",
    "        return 'audioinput.wav'\n",
    "        # waveform, sample_rate = torchaudio.load('/audioinput.wav')\n",
    "    \n",
    "    # process an image uploaded to the endpoint\n",
    "    # if content_type == JPEG_CONTENT_TYPE: return open_image(io.BytesIO(request_body))\n",
    "    # process a URL submitted to the endpoint\n",
    "    # if content_type == JSON_CONTENT_TYPE:\n",
    "    #    img_request = requests.get(request_body['url'], stream=True)\n",
    "    #    return open_image(io.BytesIO(img_request.content))\n",
    "    raise Exception('Requested unsupported ContentType in content_type: {}'.format(request_content_type))\n",
    "\n",
    "# Perform prediction on the deserialized object, with the loaded model\n",
    "def predict_fn(input_object, model):\n",
    "    logger.info(\"TYHAC: Calling model for predict\")\n",
    "    start_time = time.time()\n",
    "    predict_class,predict_idx,predict_values = model.predict(input_object)\n",
    "    print(\"--- Inference time: %s seconds ---\" % (time.time() - start_time))\n",
    "    print(f'Predicted class is {str(predict_class)}')\n",
    "    print(f'Predict confidence score is {predict_values[predict_idx.item()].item()}')\n",
    "    return dict(class_name = str(predict_class),\n",
    "        confidence = predict_values[predict_idx.item()].item())\n",
    "\n",
    "# Serialize the prediction result into the desired response content type\n",
    "def output_fn(prediction, accept=JSON_CONTENT_TYPE):        \n",
    "    logger.info('TYHAC: Serializing the predicted output.')\n",
    "    if accept == JSON_CONTENT_TYPE: return json.dumps(prediction), accept\n",
    "    raise Exception('Requested unsupported ContentType in Accept: {}'.format(accept)) \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = model_fn('tyhac-fastai-2021-08-22-23-10-40-004')\n",
    "\n",
    "    print(model.dls.vocab)\n",
    "\n",
    "    audio = input_fn('sagemaker-ap-southeast-2-ACCOUNTID/sagemaker-covid-tyhac-fastai/data/audio/0sIeyohqXMOGTqPA7RiiuyJ3AOt2-cough-shallow.wav', 'text/csv')\n",
    "    \n",
    "    predict_fn(audio, model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# from sagemaker.predictor import Predictor\n",
    "\n",
    "# class ImagePredictor(Predictor):\n",
    "#    def __init__(self, endpoint_name, sagemaker_session):\n",
    "#        super().__init__(endpoint_name, sagemaker_session=sagemaker_session, serializer=None, \n",
    "#                         deserializer=None, content_type='test/csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "model = PyTorchModel(model_data=model_artefact,\n",
    "                   source_dir='inference/',\n",
    "                   role=role, framework_version='1.5.1', py_version='py3', entry_point='serve.py',\n",
    "                   image_uri='ACCOUNTID.dkr.ecr.ap-southeast-2.amazonaws.com/tyhac-sagemaker-inference-fastai:1.0-cpu-py36'\n",
    "                  )\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.medium', wait=False) # ml.t2.medium\n",
    "print(\"Inference endpoint name: {}\".format(model.endpoint_name))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# url = <some url of an image to test>\n",
    "# img_bytes = requests.get(url).content\n",
    "response = predictor.predict('sagemaker-ap-southeast-2-ACCOUNTID/sagemaker-covid-tyhac-fastai/data/audio/0sIeyohqXMOGTqPA7RiiuyJ3AOt2-cough-shallow.wav');\n",
    "print(response)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "## make a prediction\n",
    "import boto3\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=model.endpoint_name,\n",
    "    Body='sagemaker-ap-southeast-2-ACCOUNTID/sagemaker-covid-tyhac-fastai/data/audio/0sIeyohqXMOGTqPA7RiiuyJ3AOt2-cough-shallow.wav'.format(account_id),\n",
    "    ContentType='text/csv',\n",
    ")\n",
    "\n",
    "print(\"The probability of positive label is {}\".format(response['Body'].read().decode(\"utf-8\")))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_predictor()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}